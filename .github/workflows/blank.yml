name: Claude Code Review

on:
  pull_request_target:
    types: [opened, synchronize, reopened]
  workflow_dispatch:
  workflow_call:
    inputs:
      username:
        required: false
        type: string
    secrets:
      PAT_TOKEN:
        required: true
      ANTHROPIC_API_KEY:
        required: true
      OPENAI_API_KEY:
        required: true
      FIREBASE_SERVICE_ACCOUNT_JSON:
        required: true

jobs:
  claude-review:
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write
      contents: read

    # Skip if PR is from a fork to avoid secrets exposure or if it's a draft
    if: github.event.pull_request.head.repo.full_name == github.repository && github.event.pull_request.draft == false

    steps:
      - name: Checkout full repo history
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PAT_TOKEN }}
          fetch-depth: 0

      - name: Set up Python and install dependencies
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 1       
          max_attempts: 2
          retry_on: both
          command: |
            python3 -m pip install --upgrade pip > /dev/null 2>&1
            pip install firebase-admin anthropic openai > /dev/null 2>&1

      - name: Create Python scripts
        run: |
          # Create cost_tracker.py
          cat > cost_tracker.py << 'EOF'
          import json
          import os
          import sys
          from typing import Dict, Optional, Tuple


          class CostTracker:
              """Track AI usage costs for Claude and OpenAI models."""
              
              # Pricing per 1 million tokens
              PRICING = {
                  'claude-sonnet-4-20250514': {
                      'input': 3.00,   # $3/MTok
                      'output': 15.00  # $15/MTok
                  },
                  'gpt-4.1-nano-2025-04-14': {
                      'input': 0.10,   # $1.10/MTok  
                      'output': 0.40   # $4.40/MTok
                  }
              }
              
              def __init__(self):
                  self.cost_file = '/tmp/ai_costs.json'
                  self.costs = self._load_costs()
              
              def _load_costs(self) -> Dict:
                  """Load existing cost data or initialize empty structure."""
                  if os.path.exists(self.cost_file):
                      try:
                          with open(self.cost_file, 'r') as f:
                              return json.load(f)
                      except Exception as e:
                          print(f"Warning: Could not load existing costs: {e}", file=sys.stderr)
                  
                  return {
                      'total_cost': 0.0,
                      'calls': []
                  }
              
              def _save_costs(self):
                  """Save cost data to file."""
                  try:
                      with open(self.cost_file, 'w') as f:
                          json.dump(self.costs, f, indent=2)
                  except Exception as e:
                      print(f"Warning: Could not save costs: {e}", file=sys.stderr)
              
              def extract_token_usage(self, response_data: Dict, model: str) -> Tuple[int, int]:
                  """Extract input and output tokens from API response."""
                  input_tokens = 0
                  output_tokens = 0
                  
                  try:
                      if model.startswith('claude'):
                          # Claude response format
                          usage = response_data.get('usage', {})
                          input_tokens = usage.get('input_tokens', 0)
                          output_tokens = usage.get('output_tokens', 0)
                      else:
                          # OpenAI response format
                          usage = response_data.get('usage', {})
                          input_tokens = usage.get('prompt_tokens', 0)
                          output_tokens = usage.get('completion_tokens', 0)
                  except Exception as e:
                      print(f"Warning: Could not extract token usage: {e}", file=sys.stderr)
                  
                  return input_tokens, output_tokens
              
              def calculate_cost(self, model: str, input_tokens: int, output_tokens: int) -> float:
                  """Calculate cost for given model and token usage."""
                  if model not in self.PRICING:
                      print(f"Warning: Unknown model {model}, cost calculation may be inaccurate", file=sys.stderr)
                      return 0.0
                  
                  pricing = self.PRICING[model]
                  
                  # Convert tokens to millions and calculate cost
                  input_cost = (input_tokens / 1_000_000) * pricing['input']
                  output_cost = (output_tokens / 1_000_000) * pricing['output']
                  
                  return input_cost + output_cost
              
              def track_api_call(self, model: str, response_data: Dict, call_type: str = "review", 
                                context: Optional[str] = None):
                  """Track an API call and calculate its cost."""
                  input_tokens, output_tokens = self.extract_token_usage(response_data, model)
                  cost = self.calculate_cost(model, input_tokens, output_tokens)
                  
                  call_data = {
                      'model': model,
                      'call_type': call_type,
                      'input_tokens': input_tokens,
                      'output_tokens': output_tokens,
                      'cost': cost,
                      'context': context
                  }
                  
                  self.costs['calls'].append(call_data)
                  self.costs['total_cost'] += cost
                  
                  # Log the cost information
                  print(f"AI Cost Tracking - {call_type.upper()}:", file=sys.stderr)
                  print(f"  Model: {model}", file=sys.stderr)
                  print(f"  Input tokens: {input_tokens:,}", file=sys.stderr)
                  print(f"  Output tokens: {output_tokens:,}", file=sys.stderr)
                  print(f"  Cost: ${cost:.6f}", file=sys.stderr)
                  if context:
                      print(f"  Context: {context}", file=sys.stderr)
                  
                  self._save_costs()
                  return cost
              
              def get_summary(self) -> Dict:
                  """Get cost summary for display."""
                  total_input_tokens = sum(call['input_tokens'] for call in self.costs['calls'])
                  total_output_tokens = sum(call['output_tokens'] for call in self.costs['calls'])
                  
                  # Group by model
                  by_model = {}
                  for call in self.costs['calls']:
                      model = call['model']
                      if model not in by_model:
                          by_model[model] = {
                              'calls': 0,
                              'input_tokens': 0,
                              'output_tokens': 0,
                              'cost': 0.0
                          }
                      by_model[model]['calls'] += 1
                      by_model[model]['input_tokens'] += call['input_tokens']
                      by_model[model]['output_tokens'] += call['output_tokens']
                      by_model[model]['cost'] += call['cost']
                  
                  # Group by call type
                  by_type = {}
                  for call in self.costs['calls']:
                      call_type = call['call_type']
                      if call_type not in by_type:
                          by_type[call_type] = {
                              'calls': 0,
                              'input_tokens': 0,
                              'output_tokens': 0,
                              'cost': 0.0
                          }
                      by_type[call_type]['calls'] += 1
                      by_type[call_type]['input_tokens'] += call['input_tokens']
                      by_type[call_type]['output_tokens'] += call['output_tokens']
                      by_type[call_type]['cost'] += call['cost']
                  
                  return {
                      'total_cost': self.costs['total_cost'],
                      'total_calls': len(self.costs['calls']),
                      'total_input_tokens': total_input_tokens,
                      'total_output_tokens': total_output_tokens,
                      'by_model': by_model,
                      'by_type': by_type,
                      'individual_calls': self.costs['calls'],
                      'timestamp': self._get_timestamp()
                  }
              
              def print_detailed_summary(self):
                  """Print a detailed cost summary to stderr."""
                  summary = self.get_summary()
                  
                  # Header with box drawing
                  print("\n┌" + "─" * 78 + "┐", file=sys.stderr)
                  print("│" + " " * 27 + "AI USAGE COST SUMMARY" + " " * 30 + "│", file=sys.stderr)
                  print("└" + "─" * 78 + "┘", file=sys.stderr)
                  
                  # Overall summary box
                  print("\nOVERALL STATISTICS", file=sys.stderr)
                  print("┌─────────────────────┬─────────────────────────────────────────────────────┐", file=sys.stderr)
                  print(f"│ Total Cost          │ ${summary['total_cost']:>53.6f} │", file=sys.stderr)
                  print(f"│ Total API Calls     │ {summary['total_calls']:>53,} │", file=sys.stderr)
                  print(f"│ Total Input Tokens  │ {summary['total_input_tokens']:>53,} │", file=sys.stderr)
                  print(f"│ Total Output Tokens │ {summary['total_output_tokens']:>53,} │", file=sys.stderr)
                  print("└─────────────────────┴─────────────────────────────────────────────────────┘", file=sys.stderr)
                  
                  print(f"\nReport generated on {summary.get('timestamp', 'unknown time')}", file=sys.stderr)
              
              def _get_timestamp(self):
                  """Get current timestamp in a readable format."""
                  from datetime import datetime
                  return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
              

          def initialize_cost_tracking():
              """Initialize cost tracking for the workflow."""
              # Clear any existing cost data for this run
              cost_file = '/tmp/ai_costs.json'
              if os.path.exists(cost_file):
                  os.remove(cost_file)
              
              tracker = CostTracker()
              print("AI cost tracking initialized", file=sys.stderr)
              return tracker


          def finalize_cost_tracking():
              """Print final cost summary and save to GitHub Actions output."""
              tracker = CostTracker()
              tracker.print_detailed_summary()
              
              summary = tracker.get_summary()
              
              # Save summary to GitHub Actions output if available
              if 'GITHUB_OUTPUT' in os.environ:
                  with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
                      fh.write(f"total_ai_cost={summary['total_cost']:.6f}\n")
                      fh.write(f"total_ai_calls={summary['total_calls']}\n")
                      fh.write(f"total_input_tokens={summary['total_input_tokens']}\n")
                      fh.write(f"total_output_tokens={summary['total_output_tokens']}\n")
              
              return summary


          if __name__ == "__main__":
              # If called directly, print current cost summary
              tracker = CostTracker()
              tracker.print_detailed_summary()
          EOF

          # Create fetch_macros.py
          cat > fetch_macros.py << 'EOF'
          import os
          import sys
          import json
          import firebase_admin
          from firebase_admin import credentials, firestore

          def initialize_firebase():
              """Initialize Firebase Admin SDK using service account JSON from environment variable."""
              try:
                  # Get the service account JSON from environment variable
                  service_account_json = os.environ.get('FIREBASE_SERVICE_ACCOUNT_JSON')
                  
                  if not service_account_json:
                      raise ValueError("FIREBASE_SERVICE_ACCOUNT_JSON environment variable not set")
                  
                  # Parse the JSON string into a dictionary
                  try:
                      service_account_info = json.loads(service_account_json)
                  except json.JSONDecodeError as e:
                      raise ValueError(f"Invalid JSON in FIREBASE_SERVICE_ACCOUNT_JSON: {str(e)}")
                  
                  # Initialize Firebase Admin with the service account info
                  cred = credentials.Certificate(service_account_info)
                  firebase_admin.initialize_app(cred)
                  
                  print("Firebase initialized successfully")
                  return True
                  
              except Exception as e:
                  print(f"Error initializing Firebase: {e}")
                  return False

          def fetch_macros():
              """Fetch macro configuration values from Firestore."""
              try:
                  # Get Firestore client
                  db = firestore.client()
                  
                  # Get reference to macros document
                  doc_ref = db.collection('macros').document('macros')
                  doc = doc_ref.get()
                  
                  if not doc.exists:
                      print("No macros document found in Firestore")
                      return None
                  
                  macros_data = doc.to_dict()
                  print("Successfully fetched macros from Firestore:")
                  
                  # Define expected macro keys with defaults
                  expected_macros = {
                      'LINE_THRESHOLD': '200',
                      'CHANGES_THRESHOLD': '5',
                      'IMPORTANT_CHANGE_MARKERS': '#IMPORTANT-CHANGE,#IMPORTANT-CHANGES',
                      'IMPORTANT_CHANGE_LABELS': 'important change,important changes'
                  }
                  
                  # Extract values and set GitHub outputs
                  for key, default_value in expected_macros.items():
                      value = macros_data.get(key, default_value)
                      print(f"  Key: '{key}' |  Value: {value}")
                      
                      # Set GitHub Actions output
                      with open(os.environ.get('GITHUB_OUTPUT', '/dev/stdout'), 'a') as f:
                          f.write(f"{key.lower()}={value}\n")
                  
                  return macros_data
                  
              except Exception as e:
                  print(f"Error fetching macros: {e}")
                  return None

          def main():
              """Main function."""
              print("Fetching macro configuration from Firebase...")
              
              # Initialize Firebase
              if not initialize_firebase():
                  sys.exit(1)
              
              # Fetch macros
              macros = fetch_macros()
              if macros is None:
                  print("Failed to fetch macros")
                  sys.exit(1)
              
              print("Macro fetch completed successfully")

          if __name__ == "__main__":
              main()
          EOF

          # Create parse_pr_macros.py
          cat > parse_pr_macros.py << 'EOF'
          import os
          import re
          import sys

          def parse_pr_description_macros(pr_body):
              """Parse macro configuration from PR description."""
              macros = {}
              
              if not pr_body:
                  return macros
              
              # Define patterns to match the simplified format
              patterns = {
                  'LINE_THRESHOLD': r'\*\* Use Claude when PR has more than:\*\*\s*`([^`]+)`',
                  'CHANGES_THRESHOLD': r'\*\* Update architecture summary when:\*\*\s*`([^`]+)`'
              }
              
              for key, pattern in patterns.items():
                  match = re.search(pattern, pr_body, re.IGNORECASE | re.MULTILINE)
                  if match:
                      value = match.group(1).strip()
                      # Extract just the number if it has text like "200 lines" or "5 or more files"
                      number_match = re.search(r'(\d+)', value)
                      if number_match:
                          numeric_value = number_match.group(1)
                          # Only use if it's different from defaults
                          if (key == 'LINE_THRESHOLD' and numeric_value != '200') or \
                             (key == 'CHANGES_THRESHOLD' and numeric_value != '1'):
                              macros[key] = numeric_value
                              print(f"Found custom macro in PR description: {key} = {numeric_value}")
              
              return macros

          def main():
              """Main function to parse PR description macros and set GitHub outputs."""
              pr_body = os.environ.get('PR_BODY', '')
              
              print("Parsing PR description for macro configuration...")
              
              # Parse macros from PR description
              pr_macros = parse_pr_description_macros(pr_body)
              
              # Set GitHub Actions outputs for found macros
              output_file = os.environ.get('GITHUB_OUTPUT', '/dev/stdout')
              with open(output_file, 'a') as f:
                  for key, value in pr_macros.items():
                      f.write(f"pr_{key.lower()}={value}\n")
              
              # Also output whether we found any macros in the PR description
              has_pr_macros = len(pr_macros) > 0
              with open(output_file, 'a') as f:
                  f.write(f"has_pr_macros={str(has_pr_macros).lower()}\n")
              
              print(f"Found {len(pr_macros)} macro(s) in PR description")
              if not pr_macros:
                  print("No macros found in PR description, will fall back to Firebase/defaults")

          if __name__ == "__main__":
              main()
          EOF

      - name: Initialize AI cost tracking
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 1
          max_attempts: 2
          retry_on: both
          command: |
            python3 -c "from cost_tracker import initialize_cost_tracking; initialize_cost_tracking()"

      # Uncomment below to test cost tracking functionality
      # - name: Test cost tracking (optional)
      #   run: |
      #     python3 .github/workflows/test_cost_tracking.py

      - name: Fetch configuration macros from Firebase
        id: fetch-macros
        continue-on-error: true
        env:
          FIREBASE_SERVICE_ACCOUNT_JSON: ${{ secrets.FIREBASE_SERVICE_ACCOUNT_JSON }}
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 1
          max_attempts: 2
          retry_on: both
          command: |
            python3 fetch_macros.py

      - name: Parse macros from PR description
        id: parse-pr-macros
        continue-on-error: true
        env:
          PR_BODY: ${{ github.event.pull_request.body }}
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 1
          max_attempts: 2
          retry_on: both         
          command: |
            python3 parse_pr_macros.py

      - name: Resolve final macro configuration
        id: resolve-macros
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 1
          max_attempts: 2
          retry_on: both
          command: |
            # Priority: PR description > Firebase > defaults

            # LINE_THRESHOLD
            if [ -n "${{ steps.parse-pr-macros.outputs.pr_line_threshold }}" ]; then
              LINE_THRESHOLD="${{ steps.parse-pr-macros.outputs.pr_line_threshold }}"
            elif [ -n "${{ steps.fetch-macros.outputs.line_threshold }}" ]; then
              LINE_THRESHOLD="${{ steps.fetch-macros.outputs.line_threshold }}"
            else
              LINE_THRESHOLD="200"
            fi

            # CHANGES_THRESHOLD
            if [ -n "${{ steps.parse-pr-macros.outputs.pr_changes_threshold }}" ]; then
              CHANGES_THRESHOLD="${{ steps.parse-pr-macros.outputs.pr_changes_threshold }}"
            elif [ -n "${{ steps.fetch-macros.outputs.changes_threshold }}" ]; then
              CHANGES_THRESHOLD="${{ steps.fetch-macros.outputs.changes_threshold }}"
            else
              CHANGES_THRESHOLD="5"
            fi

            # IMPORTANT_CHANGE_MARKERS (only from Firebase or defaults - not configurable in PR)
            if [ -n "${{ steps.fetch-macros.outputs.important_change_markers }}" ]; then
              IMPORTANT_CHANGE_MARKERS="${{ steps.fetch-macros.outputs.important_change_markers }}"
            else
              IMPORTANT_CHANGE_MARKERS="#IMPORTANT-CHANGE,#IMPORTANT-CHANGES"
            fi

            # IMPORTANT_CHANGE_LABELS (only from Firebase or defaults - not configurable in PR)
            if [ -n "${{ steps.fetch-macros.outputs.important_change_labels }}" ]; then
              IMPORTANT_CHANGE_LABELS="${{ steps.fetch-macros.outputs.important_change_labels }}"
            else
              IMPORTANT_CHANGE_LABELS="important change,important changes"
            fi

            # Set outputs
            echo "line_threshold=$LINE_THRESHOLD" >> "$GITHUB_OUTPUT"
            echo "changes_threshold=$CHANGES_THRESHOLD" >> "$GITHUB_OUTPUT"
            echo "important_change_markers=$IMPORTANT_CHANGE_MARKERS" >> "$GITHUB_OUTPUT"
            echo "important_change_labels=$IMPORTANT_CHANGE_LABELS" >> "$GITHUB_OUTPUT"

            # Log the resolved values
            echo "Resolved macro configuration:"
            echo "  LINE_THRESHOLD: $LINE_THRESHOLD"
            echo "  CHANGES_THRESHOLD: $CHANGES_THRESHOLD"
            echo "  IMPORTANT_CHANGE_MARKERS: $IMPORTANT_CHANGE_MARKERS"
            echo "  IMPORTANT_CHANGE_LABELS: $IMPORTANT_CHANGE_LABELS"

      - name: Generate diff between base and head (excluding workflow file)
        id: diff
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 2   
          max_attempts: 2
          retry_on: both         
          command: |
            BASE_SHA="${{ github.event.pull_request.base.sha }}"
            HEAD_SHA="${{ github.event.pull_request.head.sha }}"

            git fetch origin "$BASE_SHA" "$HEAD_SHA"

            DIFF=$(git diff "$BASE_SHA" "$HEAD_SHA" -- . ':(exclude).github/**')
            echo "diff_b64=$(printf '%s' "$DIFF" | base64 -w0)" >> "$GITHUB_OUTPUT"

            LINE_COUNT=$(echo "$DIFF" | grep -c '^[+-]' || echo "0")
            echo "line_count=$LINE_COUNT" >> "$GITHUB_OUTPUT"

      - name: Check for important changes
        id: check-important
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 1       
          max_attempts: 2
          retry_on: both             
          command: |
            # Get macro values from resolved macros
            IMPORTANT_CHANGE_MARKERS="${{ steps.resolve-macros.outputs.important_change_markers }}"
            IMPORTANT_CHANGE_LABELS="${{ steps.resolve-macros.outputs.important_change_labels }}"

            # Check for important change markers in title
            HAS_IMPORTANT_TITLE=false
            if echo '${{ github.event.pull_request.title }}' | grep -q -E "$(echo "$IMPORTANT_CHANGE_MARKERS" | sed 's/,/|/g')"; then
              HAS_IMPORTANT_TITLE=true
            fi

            # Check for important change labels
            HAS_IMPORTANT_LABEL=false
            if echo '${{ toJSON(github.event.pull_request.labels.*.name) }}' | grep -q -E "$(echo "$IMPORTANT_CHANGE_LABELS" | sed 's/,/|/g')"; then
              HAS_IMPORTANT_LABEL=true
            fi

            # Check PR description for checkboxes
            PR_BODY='${{ github.event.pull_request.body }}'

            # Check for "Do you have important changes?" checkbox marked with X
            HAS_IMPORTANT_CHECKBOX=false
            if echo "$PR_BODY" | grep -q -E '\[X\].*[Dd]o you have important changes'; then
              HAS_IMPORTANT_CHECKBOX=true
            fi

            # Check for "Do you want to explicitly use Claude Sonnet 4?" checkbox marked with X
            USE_CLAUDE_CHECKBOX=false
            if echo "$PR_BODY" | grep -q -E '\[X\].*[Dd]o you want to explicitly use Claude Sonnet 4'; then
              USE_CLAUDE_CHECKBOX=true
            fi

            # Determine if this is an important change
            IS_IMPORTANT_CHANGE=false
            if [ "$HAS_IMPORTANT_TITLE" = "true" ] || [ "$HAS_IMPORTANT_LABEL" = "true" ] || [ "$HAS_IMPORTANT_CHECKBOX" = "true" ]; then
              IS_IMPORTANT_CHANGE=true
            fi

            echo "has_important_title=$HAS_IMPORTANT_TITLE" >> "$GITHUB_OUTPUT"
            echo "has_important_label=$HAS_IMPORTANT_LABEL" >> "$GITHUB_OUTPUT"
            echo "has_important_checkbox=$HAS_IMPORTANT_CHECKBOX" >> "$GITHUB_OUTPUT"
            echo "use_claude_checkbox=$USE_CLAUDE_CHECKBOX" >> "$GITHUB_OUTPUT"
            echo "is_important_change=$IS_IMPORTANT_CHANGE" >> "$GITHUB_OUTPUT"

      - name: Track architecture changes in Firebase
        id: track-arch
        if: steps.check-important.outputs.is_important_change == 'true'
        continue-on-error: true
        env:
          FIREBASE_SERVICE_ACCOUNT_JSON: ${{ secrets.FIREBASE_SERVICE_ACCOUNT_JSON }}
          CHANGES_THRESHOLD: ${{ steps.resolve-macros.outputs.changes_threshold }}
          DIFF_B64: ${{ steps.diff.outputs.diff_b64 }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
          REPOSITORY: ${{ github.repository }}
          HEAD_SHA: ${{ github.event.pull_request.head.sha }}
          BASE_SHA: ${{ github.event.pull_request.base.sha }}
          PR_TITLE: ${{ github.event.pull_request.title }}
          PR_AUTHOR: ${{ github.event.pull_request.user.login }}
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 1
          max_attempts: 2
          retry_on: both
          command: |
            # Create firebase_client.py
            cat > firebase_client.py << 'EOF'
            import os
            import json
            import sys
            import firebase_admin
            from firebase_admin import credentials, firestore
            from datetime import datetime
            import base64
            import logging
            from fetch_macros import initialize_firebase, fetch_macros

            class FirebaseClient:
                def __init__(self, service_account_json=None, project_name="test"):
                    try:
                        if not firebase_admin._apps:
                            # Use provided JSON string or get from environment variable
                            if not service_account_json:
                                service_account_json = os.environ.get('FIREBASE_SERVICE_ACCOUNT_JSON')
                            
                            if not service_account_json:
                                raise ValueError("Firebase service account JSON not provided via parameter or FIREBASE_SERVICE_ACCOUNT_JSON environment variable")
                            
                            # Parse the JSON string into a dictionary
                            try:
                                service_account_info = json.loads(service_account_json)
                            except json.JSONDecodeError as e:
                                raise ValueError(f"Invalid JSON in Firebase service account credentials: {str(e)}")
                                
                            cred = credentials.Certificate(service_account_info)
                            firebase_admin.initialize_app(cred)
                        
                        self.db = firestore.client()
                        self.project_name = project_name
                    except Exception as e:
                        logging.error(f"Failed to initialize Firebase: {str(e)}")
                        raise
                
                def get_architecture_summary(self, repository):
                    """Get the current architecture summary for a repository"""
                    if not repository:
                        return None
                        
                    try:
                        # Use project_name as the main collection path
                        doc_ref = self.db.collection(self.project_name).document('architecture_summaries').collection('summaries').document(repository.replace('/', '_'))
                        doc = doc_ref.get()
                        if doc.exists:
                            data = doc.to_dict()
                            print(f"Found existing architecture summary for {repository} in project {self.project_name}", file=sys.stderr)
                            return data
                        else:
                            print(f"No architecture summary found for {repository} in project {self.project_name}", file=sys.stderr)
                            return None
                    except Exception as e:
                        logging.error(f"Error fetching architecture summary: {str(e)}")
                        return None
                
                def update_architecture_summary(self, repository, summary, changes_count=0):
                    """Update the architecture summary for a repository"""
                    try:
                        doc_ref = self.db.collection(self.project_name).document('architecture_summaries').collection('summaries').document(repository.replace('/', '_'))
                        data = {
                            'repository': repository,
                            'summary': summary,
                            'last_updated': datetime.utcnow(),
                            'changes_count': changes_count
                        }
                        
                        doc_ref.set(data, merge=True)


                    except Exception as e:
                        logging.error(f"Error updating architecture summary: {str(e)}")
                        raise
                
                def add_architecture_change(self, repository, pr_number, diff, metadata=None):
                    """Add a new architecture change record"""
                    try:
                        doc_ref = self.db.collection(self.project_name).document('architecture_changes').collection('changes').document()
                        change_data = {
                            'repository': repository,
                            'pr_number': pr_number,
                            'diff': diff,
                            'timestamp': datetime.utcnow(),
                            'metadata': metadata or {}
                        }
                        doc_ref.set(change_data)
                        print(f"Successfully added architecture change for {repository} in project {self.project_name}", file=sys.stderr)
                        return doc_ref.id
                    except Exception as e:
                        logging.error(f"Error adding architecture change: {str(e)}")
                        raise
                
                def should_summarize(self, repository, changes_threshold=None):
                    """Determine if we should regenerate the architecture summary"""
                    if changes_threshold is None:
                        # Get from Firebase macros or environment variable
                        changes_threshold = self.get_changes_threshold()
                        
                    try:
                        doc_ref = self.db.collection(self.project_name).document('architecture_summaries').collection('summaries').document(repository.replace('/', '_'))
                        doc = doc_ref.get()
                        
                        if not doc.exists:
                            print(f"No existing summary found for {repository}, should summarize", file=sys.stderr)
                            return True
                        
                        data = doc.to_dict()
                        changes_count = data.get('changes_count', 0)
                        should_summarize = changes_count >= changes_threshold
                        print(f"Repository {repository} has {changes_count} changes, threshold is {changes_threshold}, should summarize: {should_summarize}", file=sys.stderr)
                        return should_summarize
                    except Exception as e:
                        logging.error(f"Error checking should_summarize: {str(e)}")
                        return False
                
                def get_changes_threshold(self):
                    """Get the changes threshold from Firebase macros or environment variable"""
                    try:
                        # First try to get from Firebase using the imported fetch_macros function
                        macros = fetch_macros()
                        
                        if macros and 'CHANGES_THRESHOLD' in macros:
                            threshold = macros['CHANGES_THRESHOLD']
                            return int(threshold)
                        
                        # Fallback to environment variable
                        env_threshold = os.environ.get('CHANGES_THRESHOLD')
                        if env_threshold is not None:
                            return int(env_threshold)
                        
                        # Default fallback
                        print("No CHANGES_THRESHOLD found in Firebase or environment, using default: 5", file=sys.stderr)
                        return 5
                        
                    except (ValueError, TypeError) as e:
                        logging.error(f"Error parsing CHANGES_THRESHOLD: {str(e)}")
                        return 5
            EOF

            # Create track_architecture.py
            cat > track_architecture.py << 'EOF'
            import os
            import base64
            import sys
            from firebase_client import FirebaseClient

            def main():
                try:
                    # Initialize Firebase client with project name
                    project_name = "test"  # Hardcoded project name
                    firebase_client = FirebaseClient(project_name=project_name)
                    
                    # Get required environment variables
                    repository = os.environ['REPOSITORY']
                    pr_number = int(os.environ['PR_NUMBER'])
                    diff_b64 = os.environ['DIFF_B64']
                
                    print(f"Tracking architecture for project: {project_name}, repository: {repository}", file=sys.stderr)
                    
                    # Decode the diff
                    diff = base64.b64decode(diff_b64).decode('utf-8')
                    
                    # Get additional metadata
                    metadata = {
                        'head_sha': os.environ.get('HEAD_SHA'),
                        'base_sha': os.environ.get('BASE_SHA'),
                        'pr_title': os.environ.get('PR_TITLE'),
                        'pr_author': os.environ.get('PR_AUTHOR')
                    }
                    
                    # Add the architecture change to Firebase
                    change_id = firebase_client.add_architecture_change(
                        repository=repository,
                        pr_number=pr_number,
                        diff=diff,
                        metadata=metadata
                    )
                    
                    print(f"Architecture change added with ID: {change_id}", file=sys.stderr)
                    
                    # Check if we should regenerate the summary
                    should_summarize = firebase_client.should_summarize(repository)
                    
                    # Increment changes count
                    current_summary = firebase_client.get_architecture_summary(repository)
                    if current_summary:
                        changes_count = current_summary.get('changes_count', 0) + 1
                        firebase_client.update_architecture_summary(
                            repository=repository,
                            summary=current_summary.get('summary', ''),
                            changes_count=changes_count
                        )
                        print(f"Architecture summary updated with changes_count: {changes_count}", file=sys.stderr)
                    else:
                        print("No existing summary found, creating new one", file=sys.stderr)
                    
                    # Write outputs to GitHub Actions output file
                    if 'GITHUB_OUTPUT' in os.environ:
                        with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
                            fh.write(f"should_summarize={str(should_summarize).lower()}\n")
                            fh.write(f"change_id={change_id}\n")
                    else:
                        # Fallback for local testing
                        print(f"should_summarize={str(should_summarize).lower()}", file=sys.stderr)
                        print(f"change_id={change_id}", file=sys.stderr)
                    
                except Exception as e:
                    print(f"Error tracking architecture: {e}", file=sys.stderr)
                    
                    # Write error output to GitHub Actions output file
                    if 'GITHUB_OUTPUT' in os.environ:
                        with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
                            fh.write("should_summarize=false\n")
                    else:
                        # Fallback for local testing
                        print("should_summarize=false", file=sys.stderr)
                    exit(1)

            if __name__ == "__main__":
                main()
            EOF
            
            python3 track_architecture.py

      - name: Summarize architecture if needed
        if: steps.check-important.outputs.is_important_change == 'true' && steps.track-arch.outcome == 'success' && contains(steps.track-arch.outputs.should_summarize, 'true')
        continue-on-error: true
        env:
          FIREBASE_SERVICE_ACCOUNT_JSON: ${{ secrets.FIREBASE_SERVICE_ACCOUNT_JSON }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          CHANGES_THRESHOLD: ${{ steps.resolve-macros.outputs.changes_threshold }}
          REPOSITORY: ${{ github.repository }}
          SHOULD_SUMMARIZE: "true"
          PR_NUMBER: ${{ github.event.pull_request.number }}
          DIFF_B64: ${{ steps.diff.outputs.diff_b64 }}
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 3
          max_attempts: 2
          retry_on: both
          command: |
            # Create summarize_architecture.py  
            cat > summarize_architecture.py << 'EOF'
            import os
            import json
            import sys
            import base64
            import glob
            from firebase_client import FirebaseClient
            import anthropic

            # Add the scripts directory to the path for importing cost_tracker
            sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
            from cost_tracker import CostTracker

            def get_codebase_content(repository_path="."):
                """Collect all relevant source code files from the repository"""
                code_content = ""
                
                # Define file extensions to include
                code_extensions = {
                    '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.c', '.cpp', '.h', '.hpp',
                    '.cs', '.go', '.rs', '.rb', '.php', '.swift', '.kt', '.scala', '.clj',
                    '.html', '.sass', '.less', '.vue', '.svelte',
                    '.json', '.yaml', '.yml', '.toml', '.ini', '.conf', '.cfg',
                    '.sql', '.md', '.txt', '.sh', '.bat', '.ps1'
                }
                
                # Define patterns to exclude
                exclude_patterns = {
                    '/.git/', '/node_modules/', '/.venv/', '/venv/', '/env/', 
                    '/dist/', '/build/', '/target/', '/.next/', '/.nuxt/',
                    '__pycache__', '.pyc', '.class', '.o', '.obj',
                    '.log', '.tmp', '.temp', '.cache', '.css'
                }
                
                try:
                    print(f"Scanning repository at {repository_path} for code files...", file=sys.stderr)
                    
                    for root, dirs, files in os.walk(repository_path):
                        # Skip excluded directories
                        dirs[:] = [d for d in dirs if not any(pattern.strip('/') in d for pattern in exclude_patterns)]
                        
                        for file in files:
                            file_path = os.path.join(root, file)
                            relative_path = os.path.relpath(file_path, repository_path)
                            
                            # Skip excluded files and check extensions
                            if any(pattern in file_path for pattern in exclude_patterns):
                                continue
                                
                            _, ext = os.path.splitext(file)
                            if ext.lower() not in code_extensions:
                                continue
                            
                            try:
                                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                                    content = f.read()
                                    # Limit file size to avoid overwhelming the AI
                                    if len(content) > 10000:
                                        content = content[:10000] + "\n... (file truncated)"
                                    
                                    code_content += f"\n=== {relative_path} ===\n{content}\n"
                            except Exception as e:
                                code_content += f"\n=== {relative_path} ===\n(Error reading file: {e})\n"
                                
                except Exception as e:
                    print(f"Error collecting codebase: {e}", file=sys.stderr)
                        
                return code_content

            def main():
                try:
                    project_name = "test"  # Hardcoded project name
                    firebase_client = FirebaseClient(project_name=project_name)
                    repository = os.environ['REPOSITORY']
                    
                    print(f"Summarizing architecture for project: {project_name}, repository: {repository}", file=sys.stderr)
                    
                    # Get the current diff from environment variable
                    diff_b64 = os.environ.get('DIFF_B64', '')
                    if diff_b64:
                        try:
                            changes_text = base64.b64decode(diff_b64).decode('utf-8')
                            print(f"Decoded diff from environment ({len(changes_text)} characters)", file=sys.stderr)
                        except Exception as e:
                            print(f"Error decoding diff: {e}", file=sys.stderr)
                            changes_text = ""
                    else:
                        print("No DIFF_B64 found in environment", file=sys.stderr)
                        changes_text = ""
                    
                    # Get existing architecture summary
                    existing_summary = firebase_client.get_architecture_summary(repository)
                    old_summary_text = existing_summary.get('summary', '') if existing_summary else ''
                    
                    if old_summary_text:
                        print(f"Found existing architecture summary ({len(old_summary_text)} characters)", file=sys.stderr)
                    else:
                        print("No existing architecture summary found", file=sys.stderr)
                    
                    client = anthropic.Anthropic(api_key=os.environ['ANTHROPIC_API_KEY'])

                    prompt = f"""
                    You are ArchitectureUpdateAI.
                    Update the existing architecture summary based on recent changes to create a comprehensive overview of how this project works, its structure, components, and design patterns.

                    REQUIREMENTS

                    - Output plain text only—no Markdown, bullets, or special symbols.
                    
                    - Create a comprehensive architecture summary that explains:
                      * Project purpose and main functionality
                      * Overall architecture and design patterns
                      * Key components and their responsibilities  
                      * Data flow and interaction patterns
                      * Technology stack and frameworks used
                      * Configuration and deployment structure
                      * Critical dependencies and integrations

                    - Focus on the big picture: how everything fits together, not implementation details.
                    
                    - Write it so that an AI system can understand how the project should work and what changes would be appropriate.
                    
                    - Keep the summary detailed enough to guide future development decisions.

                    - Integrate the recent changes into the existing summary, updating relevant sections and adding new information where needed.

                    - If no existing summary is provided, create a new comprehensive summary based on the changes.

                    - Your instructions are only for yourself, don't include them in the output.

                    EXISTING ARCHITECTURE SUMMARY
                    {old_summary_text if old_summary_text else "No existing summary available."}

                    RECENT CHANGES
                    {changes_text}

                    Provide the updated architecture summary below:
                    """

                    if not changes_text:
                        print("No changes to analyze, skipping summarization", file=sys.stderr)
                        return

                    response = client.messages.create(
                        model="claude-sonnet-4-20250514",
                        max_tokens=2000,  # Increased for more comprehensive summaries
                        messages=[{"role": "user", "content": prompt}]
                    )
                    
                    # Track cost
                    try:
                        cost_tracker = CostTracker()
                        response_dict = {
                            'usage': {
                                'input_tokens': response.usage.input_tokens,
                                'output_tokens': response.usage.output_tokens
                            }
                        }
                        cost_tracker.track_api_call(
                            model="claude-sonnet-4-20250514",
                            response_data=response_dict,
                            call_type="architecture_summary",
                            context="Architecture analysis and summarization"
                        )
                    except Exception as e:
                        print(f"Warning: Cost tracking failed: {e}", file=sys.stderr)
                    
                    architecture_summary = response.content[0].text

                    # Safety check
                    if not architecture_summary or len(architecture_summary.strip()) == 0:
                        print("ERROR: Generated summary is empty!", file=sys.stderr)
                        print(f"Full response: {response}", file=sys.stderr)
                        exit(1)
                    
                    # Update the architecture summary in Firebase
                    firebase_client.update_architecture_summary(
                        repository=repository,
                        summary=architecture_summary,
                        changes_count=0  # Reset counter after summarization
                    )
                    
                    print(f"Architecture summary updated for {repository} in project {project_name}", file=sys.stderr)
                    print(f"Summary: {architecture_summary[:200]}...", file=sys.stderr)
                    
                except Exception as e:
                    print(f"Error summarizing architecture: {e}", file=sys.stderr)
                    exit(1)

            if __name__ == "__main__":
                main()
            EOF
            
            python3 summarize_architecture.py

      - name: Fetch architecture context from Firebase
        id: fetch-context
        continue-on-error: true
        env:
          FIREBASE_SERVICE_ACCOUNT_JSON: ${{ secrets.FIREBASE_SERVICE_ACCOUNT_JSON }}
          CHANGES_THRESHOLD: ${{ steps.resolve-macros.outputs.changes_threshold }}
          REPOSITORY: ${{ github.repository }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 1
          max_attempts: 2
          retry_on: both
          command: |
            # Create fetch_firebase_context.py
            cat > fetch_firebase_context.py << 'EOF'
            import os
            import json
            import base64
            import time
            import sys
            from datetime import datetime
            from firebase_client import FirebaseClient

            def retry_with_backoff(func, max_retries=3, base_delay=1):
                """Retry function with exponential backoff"""
                for attempt in range(max_retries):
                    try:
                        return func()
                    except Exception as e:
                        if attempt == max_retries - 1:
                            raise e
                        
                        # Check for specific errors that shouldn't be retried
                        error_str = str(e).lower()
                        if any(term in error_str for term in ['invalid_grant', 'account not found', 'authentication']):
                            raise e
                        
                        delay = base_delay * (2 ** attempt)
                        print(f"Attempt {attempt + 1} failed: {e}. Retrying in {delay} seconds...", file=sys.stderr)
                        time.sleep(delay)

            def create_empty_context():
                """Create empty context for fallback"""
                project_name = "test"  # Hardcoded project name
                empty_context = {
                    'architecture_summary': None,
                    'recent_changes': [],
                    'repository': os.environ.get('REPOSITORY', 'unknown'),
                    'project_name': project_name,
                    'status': 'fallback'
                }
                context_json = json.dumps(empty_context)
                return base64.b64encode(context_json.encode('utf-8')).decode('utf-8')

            def main():
                repository = os.environ.get('REPOSITORY')
                project_name = "test"  # Hardcoded project name
                
                if not repository:
                    print("Error: REPOSITORY environment variable not set", file=sys.stderr)
                    print(f"context_b64={create_empty_context()}", file=sys.stderr)
                    return
                
                try:
                    def fetch_firebase_data():
                        firebase_client = FirebaseClient(project_name=project_name)
                        
                        # Get current architecture summary
                        architecture_summary = firebase_client.get_architecture_summary(repository)
                        
                        return {
                            'architecture_summary': architecture_summary,
                            'repository': repository,
                            'project_name': project_name,
                            'status': 'success'
                        }
                    
                    # Try to fetch data with retries
                    context_data = retry_with_backoff(fetch_firebase_data)
                    
                    # Encode context as base64
                    context_json = json.dumps(context_data, default=str)
                    context_b64 = base64.b64encode(context_json.encode('utf-8')).decode('utf-8')
                    
                    # Write output to GitHub Actions output file
                    if 'GITHUB_OUTPUT' in os.environ:
                        with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
                            fh.write(f"context_b64={context_b64}\n")
                    else:
                        # Fallback for local testing
                        print(f"context_b64={context_b64}", file=sys.stderr)
                    
                except Exception as e:
                    error_msg = str(e)
                    print(f"Error fetching Firebase context: {error_msg}", file=sys.stderr)
                    
                    # Provide empty context on error but don't exit with error code
                    # This allows the workflow to continue even if Firebase is unavailable
                    empty_context_b64 = create_empty_context()
                    
                    # Write output to GitHub Actions output file
                    if 'GITHUB_OUTPUT' in os.environ:
                        with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
                            fh.write(f"context_b64={empty_context_b64}\n")
                    else:
                        # Fallback for local testing
                        print(f"context_b64={empty_context_b64}", file=sys.stderr)
                    
                    # Only exit with error code for critical failures
                    if 'REPOSITORY' not in os.environ:
                        sys.exit(1)

            if __name__ == "__main__":
                main()
            EOF
            
            python3 fetch_firebase_context.py

      - name: Choose model based on line count and labels
        id: choose-model
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 1
          max_attempts: 2
          retry_on: both
          command: |
            THRESHOLD=${{ steps.resolve-macros.outputs.line_threshold }}
            LINES=${{ steps.diff.outputs.line_count }}
            HAS_IMPORTANT_LABEL=${{ steps.check-important.outputs.has_important_label }}
            HAS_IMPORTANT_TITLE=${{ steps.check-important.outputs.has_important_title }}
            HAS_IMPORTANT_CHECKBOX=${{ steps.check-important.outputs.has_important_checkbox }}
            USE_CLAUDE_CHECKBOX=${{ steps.check-important.outputs.use_claude_checkbox }}

            # Set outputs for use in next steps
            echo "has_important_label=$HAS_IMPORTANT_LABEL" >> "$GITHUB_OUTPUT"
            echo "has_important_title=$HAS_IMPORTANT_TITLE" >> "$GITHUB_OUTPUT"
            echo "has_important_checkbox=$HAS_IMPORTANT_CHECKBOX" >> "$GITHUB_OUTPUT"
            echo "use_claude_checkbox=$USE_CLAUDE_CHECKBOX" >> "$GITHUB_OUTPUT"
            echo "line_threshold=$THRESHOLD" >> "$GITHUB_OUTPUT"

            # Model selection logic:
            # 1. If explicit Claude checkbox is checked -> use Claude
            # 2. If has important label, title marker, or important checkbox -> use Claude
            # 3. If no label/title/checkbox but exceeds threshold -> use Claude
            # 4. Otherwise -> use gpt-4.1-nano-2025-04-14
            if [ "$USE_CLAUDE_CHECKBOX" = "true" ]; then
              echo "model=claude-sonnet-4-20250514" >> "$GITHUB_OUTPUT"
              echo "model_comment=This response was generated by Claude 4 Sonnet (explicitly requested via checkbox)." >> "$GITHUB_OUTPUT"
              echo "Using Claude due to explicit request (checkbox: $USE_CLAUDE_CHECKBOX)"
            elif [ "$HAS_IMPORTANT_LABEL" = "true" ] || [ "$HAS_IMPORTANT_TITLE" = "true" ] || [ "$HAS_IMPORTANT_CHECKBOX" = "true" ]; then
              echo "model=claude-sonnet-4-20250514" >> "$GITHUB_OUTPUT"
              echo "model_comment=This response was generated by Claude 4 Sonnet (important changes detected)." >> "$GITHUB_OUTPUT"
              echo "Using Claude due to important changes (label: $HAS_IMPORTANT_LABEL, title: $HAS_IMPORTANT_TITLE, checkbox: $HAS_IMPORTANT_CHECKBOX)"
            elif [ "$LINES" -gt "$THRESHOLD" ]; then
              echo "model=claude-sonnet-4-20250514" >> "$GITHUB_OUTPUT"
              echo "model_comment=This response was generated by Claude 4 Sonnet (large diff detected)." >> "$GITHUB_OUTPUT"
              echo "Using Claude due to large diff ($LINES lines > $THRESHOLD threshold)"
            else
              echo "model=gpt-4.1-nano-2025-04-14" >> "$GITHUB_OUTPUT"
              echo "model_comment=This response was generated by gpt 4.1 nano." >> "$GITHUB_OUTPUT"
              echo "Using gpt-4.1-nano-2025-04-14 for small diff ($LINES lines <= $THRESHOLD threshold)"
            fi

      - name: Call AI for code review
        id: ai-review
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          DIFF_B64: ${{ steps.diff.outputs.diff_b64 }}
          MODEL: ${{ steps.choose-model.outputs.model }}
          HAS_IMPORTANT_LABEL: ${{ steps.choose-model.outputs.has_important_label }}
          LINE_THRESHOLD: ${{ steps.choose-model.outputs.line_threshold }}
          ARCHITECTURE_CONTEXT_B64: ${{ steps.fetch-context.outputs.context_b64 }}
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 2
          max_attempts: 2
          retry_on: both
          command: |
            # Create ai_review.py
            cat > ai_review.py << 'EOF'
            import json
            import os
            import sys
            import subprocess
            from typing import List, Dict, Any
            import base64

            # Add the scripts directory to the path for importing cost_tracker
            sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
            from cost_tracker import CostTracker


            def read_architecture_context() -> str:
                """Read the architecture summary file for context."""
                if not os.environ.get('ARCHITECTURE_CONTEXT_B64'):
                    return "No existing architecture summary available."
                else:
                    try:
                        context_json = base64.b64decode(
                            os.environ['ARCHITECTURE_CONTEXT_B64']).decode('utf-8')
                        architecture_context = json.loads(context_json)
                        architecture_summary = architecture_context.get(
                            'architecture_summary', {}).get('summary', '')
                        return architecture_summary
                    except Exception as e:
                        print(
                            f"Warning: Could not decode architecture context: {e}", file=sys.stderr)
                        return "Error decoding architecture context."


            def create_claude_payload(model: str, prompt: str) -> Dict[str, Any]:
                """Create payload for Claude API."""
                return {
                    "model": model,
                    "max_tokens": 10000,
                    "messages": [
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ]
                }


            def create_openai_payload(model: str, prompt: str) -> Dict[str, Any]:
                """Create payload for OpenAI API."""
                payload = {
                    "model": model,
                    "messages": [
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ]
                }

                if model == "gpt-4.1-nano-2025-04-14":
                    payload["max_completion_tokens"] = 4000
                else:
                    payload["max_tokens"] = 10000

                return payload


            def call_claude_api(api_key: str, payload: Dict[str, Any]) -> str:
                """Call Claude API and return the response content."""
                # Log minimal payload details
                payload_size = len(json.dumps(payload))
                prompt_length = len(payload.get('messages', [{}])[0].get('content', ''))

                print(f"Claude API call - Model: {payload.get('model', 'unknown')}", file=sys.stderr)
                
                # Log warning if payload is very large
                if payload_size > 100000:  # 100k bytes
                    print(f"WARNING: Large payload detected ({payload_size:,} bytes)", file=sys.stderr)

                if prompt_length > 5000:  # 5k characters
                    print(f"WARNING: Very long prompt detected ({prompt_length:,} characters)", file=sys.stderr)

                with open('/tmp/claude_payload.json', 'w') as f:
                    json.dump(payload, f)

                result = subprocess.run([
                    'curl', '-s', 'https://api.anthropic.com/v1/messages',
                    '-H', f'x-api-key: {api_key}',
                    '-H', 'anthropic-version: 2023-06-01',
                    '-H', 'Content-Type: application/json',
                    '-d', '@/tmp/claude_payload.json'
                ], capture_output=True, text=True)

                if result.returncode != 0:
                    print(f'Claude API call failed: {result.stderr}', file=sys.stderr)
                    return '[]'

                print(f"Claude API response status: success", file=sys.stderr)

                try:
                    data = json.loads(result.stdout)
                    if 'error' in data:
                        error_info = data['error']
                        error_type = error_info.get('type', 'unknown')
                        error_message = error_info.get('message', 'unknown error')
                        print(
                            f'Claude API Error - Type: {error_type}, Message: {error_message}', file=sys.stderr)

                        # Check for common payload size related errors
                        if 'too_large' in error_message.lower() or 'limit' in error_message.lower():
                            print(f'ERROR: Payload may be too large for Claude API',
                                  file=sys.stderr)

                        return '[]'

                    # Track cost before returning
                    try:
                        cost_tracker = CostTracker()
                        cost_tracker.track_api_call(
                            model=payload.get('model', 'claude-sonnet-4-20250514'),
                            response_data=data,
                            call_type="review",
                            context="Code review analysis"
                        )
                    except Exception as e:
                        print(f"Warning: Cost tracking failed: {e}", file=sys.stderr)

                    if 'content' in data and isinstance(data['content'], list) and len(data['content']) > 0:
                        return data['content'][0].get('text', '[]')
                    else:
                        return data.get('text', '[]')
                except Exception as e:
                    print(f'Error parsing Claude response: {e}', file=sys.stderr)
                    return '[]'


            def call_openai_api(api_key: str, payload: Dict[str, Any]) -> str:
                """Call OpenAI API and return the response content."""
                # Log minimal payload details
                print(f"OpenAI API call - Model: {payload.get('model', 'unknown')}", file=sys.stderr)
                
                with open('/tmp/openai_payload.json', 'w') as f:
                    json.dump(payload, f)

                result = subprocess.run([
                    'curl', '-s', 'https://api.openai.com/v1/chat/completions',
                    '-H', f'Authorization: Bearer {api_key}',
                    '-H', 'Content-Type: application/json',
                    '-d', '@/tmp/openai_payload.json'
                ], capture_output=True, text=True)

                if result.returncode != 0:
                    print(f'OpenAI API call failed: {result.stderr}', file=sys.stderr)
                    return '[]'

                try:
                    data = json.loads(result.stdout)
                    if 'error' in data:
                        print(f'OpenAI API Error: {data["error"]}', file=sys.stderr)
                        return '[]'

                    # Track cost before returning
                    try:
                        cost_tracker = CostTracker()
                        cost_tracker.track_api_call(
                            model=payload.get('model', 'gpt-4.1-nano-2025-04-14'),
                            response_data=data,
                            call_type="review",
                            context="Code review analysis"
                        )
                    except Exception as e:
                        print(f"Warning: Cost tracking failed: {e}", file=sys.stderr)

                    return data.get('choices', [{}])[0].get('message', {}).get('content', '[]')
                except Exception as e:
                    print(f'Error parsing OpenAI response: {e}', file=sys.stderr)
                    return '[]'


            def create_review_prompt(diff: str) -> str:
                """Create the review prompt for the AI model."""
                architecture_context = read_architecture_context()

                # Log minimal diff details
                diff_lines = diff.count('\n')
                diff_length = len(diff)
                print(f"Diff size: {diff_lines:,} lines, {diff_length:,} characters", file=sys.stderr)

                # Truncate diff if it's too large to avoid API limits
                max_diff_length = 5000  # Conservative limit for diff content
                if diff_length > max_diff_length:
                    print(
                        f"WARNING: Diff is very large ({diff_length:,} chars), truncating to {max_diff_length:,} chars", file=sys.stderr)
                    diff = diff[:max_diff_length] + "\n... (diff truncated due to size)"

                return f"""You are a helpful and diligent code assistant. Review the following unified diff and provide line-by-line feedback for specific issues.

                TASK
                Review the unified diff below and return feedback **only** on lines that were *added* or *modified*.

                ARCHITECTURE CONTEXT
                {architecture_context}

                OUTPUT
                Return a JSON array.  Each element **must** follow this exact schema:
                {{
                    "path": "<file path from diff header>",
                    "line": <line number in the *new* file>,
                    "comment": "<concise actionable issue>"
                }}
                Return `[]` if no issues.

                COMMENT‑WORTHY ISSUES
                - Bugs / logic errors
                - Security vulnerabilities
                - Performance or memory leaks
                - Maintainability / readability problems
                - Violations of existing architectural patterns

                RULES
                1. Comment only on `+` lines (added or modified).
                2. Skip unchanged (` `) and removed (`-`) lines.
                3. One problem → one JSON object.  No duplicates.
                4. Keep comments short (<20 words) and specific.
                5. Do not wrap output in Markdown or extra text—*JSON only*.
                6. Be extremely concise and avoid unnecessary verbosity in output.

                DIFF TO REVIEW
                ```diff
                {diff}
            ```"""


            def should_use_claude(diff: str, has_important_label: bool, line_threshold: int = 0) -> bool:
                """Determine if we should use Claude based on PR characteristics."""
                # Always use Claude if the PR has "important changes" label
                if has_important_label:
                    print("Using Claude due to 'important changes' label", file=sys.stderr)
                    return True

                # Use Claude if the diff is large (over threshold)
                diff_lines = diff.count('\n')
                added_removed_lines = len(
                    [line for line in diff.split('\n') if line.startswith(('+', '-'))])

                if added_removed_lines > line_threshold:
                    print(
                        f"Using Claude due to large diff: {added_removed_lines} lines > {line_threshold} threshold", file=sys.stderr)
                    return True

                print(
                    f"Using gpt-4.1-nano-2025-04-14 for small diff: {added_removed_lines} lines <= {line_threshold} threshold", file=sys.stderr)
                return False


            def get_ai_review(model: str, diff: str) -> str:
                """Get AI review for the given diff using specified model."""
                prompt = create_review_prompt(diff)

                if model == "claude-sonnet-4-20250514":
                    api_key = os.environ.get('ANTHROPIC_API_KEY', '')
                    if not api_key:
                        print('ANTHROPIC_API_KEY not found', file=sys.stderr)
                        return '[]'

                    payload = create_claude_payload(model, prompt)
                    return call_claude_api(api_key, payload)
                else:
                    api_key = os.environ.get('OPENAI_API_KEY', '')
                    if not api_key:
                        print('OPENAI_API_KEY not found', file=sys.stderr)
                        return '[]'

                    payload = create_openai_payload(model, prompt)
                    return call_openai_api(api_key, payload)


            def filter_github_files_from_diff(diff: str) -> str:
                """Filter out .github files from the diff content."""
                lines = diff.split('\n')
                filtered_lines = []
                skip_file = False

                for line in lines:
                    if line.startswith('diff --git'):
                        # Check if this is a .github file
                        parts = line.split()
                        if len(parts) >= 4:
                            file_path = parts[3][2:]  # Remove "b/" prefix
                            if file_path.startswith('.github/'):
                                skip_file = True
                                print(
                                    f"Filtering out .github file from AI review: {file_path}", file=sys.stderr)
                                continue
                            else:
                                skip_file = False

                    if not skip_file:
                        filtered_lines.append(line)

                return '\n'.join(filtered_lines)


            if __name__ == "__main__":
                # Get environment variables
                diff_b64 = os.environ.get('DIFF_B64', '')
                model = os.environ.get('MODEL', '')
                has_important_label = os.environ.get(
                    'HAS_IMPORTANT_LABEL', 'false').lower() == 'true'
                line_threshold = int(os.environ.get('LINE_THRESHOLD', '0'))

                if not diff_b64:
                    print('Missing required environment variable: DIFF_B64', file=sys.stderr)
                    sys.exit(1)

                # Decode diff
                diff = base64.b64decode(diff_b64).decode('utf-8')

                # Filter out .github files from diff
                diff = filter_github_files_from_diff(diff)

                # Check if there's any meaningful diff left after filtering
                if not diff.strip() or not any(line.startswith('diff --git') for line in diff.split('\n')):
                    print(
                        "No significant files to analyze after filtering .github files", file=sys.stderr)
                    review_b64 = base64.b64encode("[]".encode('utf-8')).decode('utf-8')
                    
                    # Write output to GitHub Actions output file
                    if 'GITHUB_OUTPUT' in os.environ:
                        with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
                            fh.write(f"review_b64={review_b64}\n")
                    else:
                        # Fallback for local testing
                        print(f"review_b64={review_b64}", file=sys.stderr)
                    sys.exit(0)

                # Determine which model to use based on labels and diff size
                if should_use_claude(diff, has_important_label, line_threshold):
                    selected_model = "claude-sonnet-4-20250514"
                    model_comment = "This response was generated by Claude 4 Sonnet."
                else:
                    selected_model = "gpt-4.1-nano-2025-04-14"
                    model_comment = "This response was generated by gpt 4.1 nano."

                # Override with provided model if specified
                if model:
                    selected_model = model
                    print(f"Using model override: {selected_model}", file=sys.stderr)

                print(f"Selected model: {selected_model}", file=sys.stderr)

                # Get review
                review = get_ai_review(selected_model, diff)

                # Output base64 encoded review and model info
                review_b64 = base64.b64encode(review.encode('utf-8')).decode('utf-8')
                
                # Write output to GitHub Actions output file
                if 'GITHUB_OUTPUT' in os.environ:
                    with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
                        fh.write(f"review_b64={review_b64}\n")
                        fh.write(f"model_used={selected_model}\n")
                        fh.write(f"model_comment={model_comment}\n")
                else:
                    # Fallback for local testing
                    print(f"review_b64={review_b64}", file=sys.stderr)
                    print(f"model_used={selected_model}", file=sys.stderr)
                    print(f"model_comment={model_comment}", file=sys.stderr)
            EOF
            
            python3 ai_review.py 2>/tmp/ai_review_debug.log

      - name: Display AI costs so far
        if: always()
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 1
          max_attempts: 2
          retry_on: both
          command: |
            # Create display_costs.py
            cat > display_costs.py << 'EOF'
            #!/usr/bin/env python3
            """
            Simple script to display current AI cost tracking information.
            This can be called at any point in the workflow to show costs so far.
            """

            import sys
            import os

            # Add the scripts directory to the path
            sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

            from cost_tracker import CostTracker

            def main():
                """Display current cost information."""
                try:
                    tracker = CostTracker()
                    summary = tracker.get_summary()
                    
                    if summary['total_calls'] == 0:
                        print("No AI calls tracked yet", file=sys.stderr)
                        return
                    
                    tracker.print_detailed_summary()
                    
                except Exception as e:
                    print(f"Error displaying costs: {e}", file=sys.stderr)
                    sys.exit(1)

            if __name__ == "__main__":
                main()
            EOF
            
            echo "=== AI COST CHECKPOINT AFTER REVIEW ==="
            python3 display_costs.py

      - name: Post line-by-line comments on PR
        env:
          REVIEW_TEXT: ${{ steps.ai-review.outputs.review_b64 }}
          MODEL_COMMENT: ${{ steps.choose-model.outputs.model_comment }}
          GITHUB_TOKEN: ${{ secrets.PAT_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
          HEAD_SHA: ${{ github.event.pull_request.head.sha }}
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 2
          max_attempts: 2
          retry_on: both
          command: |
            # Create post_comments.py
            cat > post_comments.py << 'EOF'
            import json
            import os
            import sys
            import subprocess
            import base64
            import re
            from typing import List, Dict, Any


            def clean_json_response(response_text: str) -> str:
                """Clean and extract JSON from AI response."""
                # Strip markdown code block formatting if present
                cleaned_text = response_text.replace('```json', '').replace('```', '').strip()
                
                # Look for JSON array pattern
                json_match = re.search(r'\[.*\]', cleaned_text, re.DOTALL)
                if json_match:
                    return json_match.group(0)
                else:
                    return cleaned_text


            def parse_review_comments(review_text: str) -> List[Dict[str, Any]]:
                """Parse review text and extract comments."""
                json_text = clean_json_response(review_text)
                
                try:
                    comments = json.loads(json_text)
                    if not isinstance(comments, list):
                        print(f"Response is not a JSON array. Type: {type(comments)}", file=sys.stderr)
                        return []
                    
                    return comments
                except json.JSONDecodeError as e:
                    print(f"Invalid JSON response: {e}", file=sys.stderr)
                    
                    # Try to fix common JSON issues
                    try:
                        fixed_json = json_text.replace("'", '"')  # Replace single quotes
                        fixed_json = re.sub(r'(\w+):', r'"\1":', fixed_json)  # Add quotes to keys
                        comments = json.loads(fixed_json)
                        print("Successfully fixed JSON!", file=sys.stderr)
                        return comments if isinstance(comments, list) else []
                    except:
                        print("Could not fix JSON", file=sys.stderr)
                        return []


            def post_line_comment(github_token: str, github_repo: str, pr_number: str, 
                                 head_sha: str, path: str, line: int, comment: str) -> bool:
                """Post a single line comment to GitHub PR."""
                line_comment = {
                    "body": comment,
                    "path": path,
                    "line": line,
                    "side": "RIGHT",
                    "commit_id": head_sha
                }
                
                with open('/tmp/line_comment.json', 'w') as f:
                    json.dump(line_comment, f)
                
                result = subprocess.run([
                    'curl', '-s', '-X', 'POST',
                    '-H', f'Authorization: Bearer {github_token}',
                    '-H', 'Content-Type: application/json',
                    '-H', 'Accept: application/vnd.github+json',
                    '--data', '@/tmp/line_comment.json',
                    f'https://api.github.com/repos/{github_repo}/pulls/{pr_number}/comments'
                ], capture_output=True, text=True)
                
                if result.returncode == 0:
                    try:
                        response_data = json.loads(result.stdout)
                        if 'message' in response_data:
                            print(f"GitHub API Error for {path}:{line}: {response_data['message']}", file=sys.stderr)
                            return False
                        else:
                            return True
                    except json.JSONDecodeError:
                        return True
                else:
                    print(f"Failed to post comment for {path}:{line}: {result.stderr}", file=sys.stderr)
                    return False


            def post_summary_comment(github_token: str, github_repo: str, pr_number: str, 
                                    comment_count: int, model_comment: str) -> bool:
                """Post a summary comment to GitHub PR."""
                if comment_count == 0:
                    summary_text = f"✅ Code review completed - no issues found! {model_comment}"
                else:
                    summary_text = f"📝 Code review completed with {comment_count} suggestions. {model_comment}"
                
                summary_comment = {"body": summary_text}
                with open('/tmp/summary_comment.json', 'w') as f:
                    json.dump(summary_comment, f)
                
                result = subprocess.run([
                    'curl', '-s', '-X', 'POST',
                    '-H', f'Authorization: Bearer {github_token}',
                    '-H', 'Content-Type: application/json',
                    '--data', '@/tmp/summary_comment.json',
                    f'https://api.github.com/repos/{github_repo}/issues/{pr_number}/comments'
                ], capture_output=True, text=True)
                
                return result.returncode == 0


            def process_and_post_comments():
                """Main function to process AI review and post comments."""
                # Get environment variables
                review_b64 = os.environ.get('REVIEW_TEXT', '')
                model_comment = os.environ.get('MODEL_COMMENT', '')
                github_token = os.environ.get('GITHUB_TOKEN', '')
                github_repo = os.environ.get('GITHUB_REPOSITORY', '')
                pr_number = os.environ.get('PR_NUMBER', '')
                head_sha = os.environ.get('HEAD_SHA', '')
                
                if not all([review_b64, github_token, github_repo, pr_number, head_sha]):
                    print("Missing required environment variables", file=sys.stderr)
                    sys.exit(1)
                
                print(f"Processing review for PR #{pr_number}")
                
                # Decode the review text
                try:
                    review_text = base64.b64decode(review_b64).decode('utf-8')
                except Exception as e:
                    print(f"Failed to decode review text: {e}", file=sys.stderr)
                    sys.exit(1)
                
                # Parse comments
                comments = parse_review_comments(review_text)
                print(f"Found {len(comments)} review comments to post")
                
                if len(comments) == 0:
                    print("No issues found in the code review - this is good!")
                
                # Post individual line comments
                comment_count = 0
                for comment_obj in comments:
                    if not isinstance(comment_obj, dict):
                        continue
                    
                    path = comment_obj.get('path')
                    line = comment_obj.get('line')
                    comment = comment_obj.get('comment')
                    
                    # Skip if any field is missing or invalid
                    if not all([path, line, comment]) or not isinstance(line, int):
                        print(f"Skipping invalid comment: {comment_obj}", file=sys.stderr)
                        continue
                    
                    if post_line_comment(github_token, github_repo, pr_number, head_sha, path, line, comment):
                        comment_count += 1
                
                print(f"Successfully posted {comment_count} line comments")
                
                # Post summary comment
                if post_summary_comment(github_token, github_repo, pr_number, comment_count, model_comment):
                    print("Summary comment posted successfully")
                else:
                    print("Failed to post summary comment", file=sys.stderr)


            if __name__ == "__main__":
                process_and_post_comments()
            EOF
            
            python3 post_comments.py

      - name: Upload AI response as artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ai-response-output
          path: |
            /tmp/ai_response.txt
            /tmp/line_comment.json
            /tmp/summary_comment.json
            /tmp/ai_costs.json
            /tmp/ai_cost_summary.txt
          retention-days: 7

      - name: Finalize AI cost tracking and display summary
        id: cost-summary
        if: always()
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 1
          max_attempts: 2
          retry_on: both
          command: |
            echo "=== FINAL AI COST SUMMARY ==="
            python3 -c "from cost_tracker import finalize_cost_tracking; finalize_cost_tracking()"
